# use this to test ollama running local llm
# also for deployment try llama with there free tier to test if the model is working for provided pdf's
# for testing the model with the provided pdf's use the following command

